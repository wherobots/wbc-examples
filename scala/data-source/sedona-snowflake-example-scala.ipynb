{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b773bee-fe1c-47ff-a5b4-3cc0a840c9e8",
   "metadata": {},
   "source": [
    "# Import Apache Sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a554ab-2f05-4534-8eea-d92474cb1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.sedona.spark.SedonaContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff8853-9ea0-434b-9f22-507da444e7da",
   "metadata": {},
   "source": [
    "# Define Sedona context if not defined yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10b7e8-b3ca-4276-84db-cc51395c537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val config = SedonaContext.builder()\n",
    "    .getOrCreate()\n",
    "val sedona = SedonaContext.create(config)\n",
    "val sc = sedona.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d2a2c-d680-4502-833e-7235dd570895",
   "metadata": {},
   "source": [
    "# Set Snowflake connection and context options.\n",
    "\n",
    "Full list of possible configuration options can be found [here](https://docs.snowflake.com/en/user-guide/spark-connector-use#label-spark-options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdce53-792e-4d93-a56b-85d1439780f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85e3fb-afbc-4685-867f-19baaacc5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Connection options\n",
    "val snowflakeUrl = \"<SNOWFLAKE_URL>\" // <account_identifier>.snowflakecomputing.com\n",
    "val username = \"<SNOWFLAKE_USERNAME>\"\n",
    "val password = \"<SNOWFLAKE_PASSWORD>\"\n",
    "\n",
    "//Context options\n",
    "val database = \"<SNOWFLAKE_DB_NAME>\"\n",
    "val schema = \"<DB_SCHEMA>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0c25d-f8a8-40ff-8529-915244ce6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "val sfOptions = Map(\"sfUrl\" -> snowflakeUrl, \"sfUser\" -> username, \"sfPassword\" -> password, \"sfDatabase\" -> database, \"sfSchema\" -> schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e13e0-2b5c-455a-9ba7-1afb11b0e0b1",
   "metadata": {},
   "source": [
    "# Read entire table from snowflake into a Sedona Dataframe\n",
    "A `dbtable` option with the table_name as value can be passed to the spark session object to read the entire table contents into the dataframe. Essentially, run a 'SELECT * FROM table' query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc280dde-dd0d-4077-81aa-79aa413d122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val src_table_name = \"city_tbl_geom\" //source table name in Snowflake\n",
    "val df = sedona.read.format(SNOWFLAKE_SOURCE_NAME)\n",
    "    .options(sfOptions)\n",
    "    .option(\"dbtable\", src_table_name)\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c259cf-4ea7-44a2-8c7a-e7c58f8217ec",
   "metadata": {},
   "source": [
    "# Read a particular query result from snowflake into a Sedona Dataframe\n",
    "A `query` option with the desired query as value can be passed to the sedona context object to read the result of the query into the dataframe. \n",
    "\n",
    "By default, query and predicate pushdown in this execution. \n",
    "If you wish to disable pushdown, a `autopushdown` option with value `off` can be passed to the sedona context object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87668339-de49-48e0-a73a-f0ecbd1e2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "val query = s\"SELECT GEOM, CITY_NAME FROM $src_table_name WHERE CITY_NAME = 'Seattle'\" //custom query to run\n",
    "val df_query = sedona.read.format(SNOWFLAKE_SOURCE_NAME)\n",
    "            .options(sfOptions)\n",
    "            .option(\"query\", query)\n",
    "            .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80941a-e1d7-4748-9baa-3f0bbd2564b3",
   "metadata": {},
   "source": [
    "# Create Sedona Geometry type column\n",
    "Snowflake serializes geometries as GeoJSON and hence the dataframe will be populated with GeoJSON strings in the geometry column.\n",
    "The GeoJSON strings can be converted to Sedona Geometry types using `ST_GeomFromGeoJSON` exposed via Sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee280a1-e491-4bbf-8416-5173643b210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df_city = df.selectExpr(\"ST_GeomFromGeoJSON(GEOM) as geom\", \"CITY_NAME\")\n",
    "val df_seattle = df_query.selectExpr(\"ST_GeomFromGeoJSON(GEOM) as geom\", \"CITY_NAME\")\n",
    "\n",
    "//create a table for use in subsequent queries\n",
    "df_city.createOrReplaceTempView(\"city_table\")\n",
    "df_seattle.createOrReplaceTempView(\"seattle_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1804e3a-45a4-47ad-bf75-e17492cc869c",
   "metadata": {},
   "source": [
    "# Operate on geospatial data using Sedona\n",
    "Now, any desired processing can be performed on the loaded geospatial data with Sedona's extensive [vector function catalog](https://docs.wherobots.services/1.1.0/references/wherobots-compute/vector-data/Overview/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64cafee-f96b-4d53-a7de-170245bb0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "val new_york_point = \"POINT (-74.00 40.71)\"\n",
    "val df_ny = sedona.sql(s\"SELECT ST_GeomFromWKT('$new_york_point') as new_york\")\n",
    "df_ny.createOrReplaceTempView(\"new_york_table\")\n",
    "val df_dist_from_ny = sedona.sql(\"SELECT ST_AsGeoJson(geom) as geom, ST_DistanceSphere(geom, new_york) as dist_from_ny, CITY_NAME from city_table, new_york_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debc565-4200-439d-8495-d1a0588ea7ac",
   "metadata": {},
   "source": [
    "# Write computed data back to Snowflake\n",
    "\n",
    "A Sedona Dataframe can be written back to Snowflake using the write() method of the sedona context object. \n",
    "Same as with the read() method, a map `sfOptions` must be passed with the necessary connection and context options.\n",
    "\n",
    "Provide a `dbtable` option to specify the name of the destination table.\n",
    "\n",
    "Also, provide a [save mode](https://spark.apache.org/docs/1.6.0/api/java/org/apache/spark/sql/SaveMode.html) parameter to specify handling collisions with existing tables if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3a03e-f9ce-4507-8cd9-e168f43a85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val destination_table = \"distance_from_ny\" //destination table name in Snowflake\n",
    "val save_mode = \"append\" //Append data to the table if the table already exists with some data. Other possible values are: errorifexists, ignore, overwrite.\n",
    "df_dist_from_ny.write.format(SNOWFLAKE_SOURCE_NAME)\n",
    "                    .options(sfOptions)\n",
    "                    .option(\"dbtable\", destination_table)\n",
    "                    .mode(saveMode=save_mode)\n",
    "                    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5ad06-3128-4ca3-b91a-8e0b90c41609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
